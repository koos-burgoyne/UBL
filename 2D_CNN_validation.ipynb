{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bdebafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy library for use in ...\n",
    "import numpy as np\n",
    "\n",
    "amino_acids = {\n",
    "    \"A\":0, \"R\":1, \"N\":2, \"D\":3, \"C\":4, \"Q\":5, \"E\":6, \"G\":7, \"H\":8, \"I\":9, \"L\":10, \"K\":11, \"M\":12, \"F\":13, \"P\":14, \"S\":15, \"T\":16, \"W\":17, \"Y\":18, \"V\":19\n",
    "}\n",
    "\n",
    "VHSE_descriptors = {\n",
    "    0:{\"A\":0.15, \"R\":-1.47, \"N\":-0.99, \"D\":-1.15, \"C\":0.18, \"Q\":-.96, \"E\":-1.18, \"G\":-0.2, \"H\":-0.43, \"I\":1.27, \"L\":11.36, \"K\":-1.17, \"M\":1.01, \"F\":1.52, \"P\":0.22, \"S\":-0.67, \"T\":-0.34, \"W\":1.5, \"Y\":0.61, \"V\":0.76},\n",
    "    1:{\"A\":-1.11, \"R\":1.45, \"N\":0,     \"D\":0.67, \"C\":-1.67, \"Q\":0.12, \"E\":0.4, \"G\":-1.53, \"H\":-0.25, \"I\":-0.14, \"L\":0.07, \"K\":0.7, \"M\":-0.53, \"F\":0.61, \"P\":-0.17, \"S\":-0.86, \"T\":-0.51, \"W\":2.06, \"Y\":1.6, \"V\":-0.92},\n",
    "    2:{\"A\":-1.35, \"R\":1.24, \"N\":-0.37, \"D\":-0.41, \"C\":-0.46, \"Q\":0.18, \"E\":0.1, \"G\":-2.63, \"H\":0.37, \"I\":0.3, \"L\":0.26, \"K\":0.7, \"M\":0.43, \"F\":0.96, \"P\":-0.5, \"S\":-1.07, \"T\":-0.55, \"W\":1.79, \"Y\":1.17, \"V\":0.17},\n",
    "    3:{\"A\":-0.92, \"R\":1.27, \"N\":0.69, \"D\":-0.01, \"C\":-.021, \"Q\":0.16, \"E\":0.36, \"G\":2.28, \"H\":0.19, \"I\":-1.8, \"L\":-0.8, \"K\":0.8, \"M\":0, \"F\":-0.16, \"P\":0.05, \"S\":-0.41, \"T\":-1.06, \"W\":0.75, \"Y\":0.73, \"V\":-1.91},\n",
    "    4:{\"A\":0.02, \"R\":1.55, \"N\":-0.55, \"D\":-2.68, \"C\":0, \"Q\":0.09, \"E\":-2.16, \"G\":-0.53, \"H\":0.51, \"I\":0.3, \"L\":0.22, \"K\":1.64, \"M\":0.23, \"F\":0.25, \"P\":-0.01, \"S\":-0.32, \"T\":0.01, \"W\":0.75, \"Y\":0.53, \"V\":0.22},\n",
    "    5:{\"A\":-0.91, \"R\":1.47, \"N\":0.85, \"D\":1.31, \"C\":1.2, \"Q\":0.42, \"E\":-0.17, \"G\":-1.18, \"H\":1.28, \"I\":-1.61, \"L\":-1.37, \"K\":0.67, \"M\":0.1, \"F\":0.28, \"P\":-1.43, \"S\":0.27, \"T\":-0.01, \"W\":-0.13, \"Y\":0.25, \"V\":-1.4},\n",
    "    6:{\"A\":0.36, \"R\":1.3, \"N\":0.73, \"D\":0.03, \"C\":-1.61, \"Q\":-0.2, \"E\":0.91, \"G\":2.01, \"H\":0.93, \"I\":-0.16, \"L\":0.08, \"K\":1.63, \"M\":-0.86, \"F\":-1.33, \"P\":-0.19, \"S\":-0.64, \"T\":-0.79, \"W\":-1.06, \"Y\":-0.96, \"V\":-0.24},\n",
    "    7:{\"A\":-0.48, \"R\":0.83, \"N\":-0.8, \"D\":0.56, \"C\":-0.19, \"Q\":-0.41, \"E\":0.02, \"G\":-1.34, \"H\":0.65, \"I\":-0.13, \"L\":-0.62, \"K\":0.13, \"M\":-0.68, \"F\":-0.2, \"P\":3.56, \"S\":0.11, \"T\":0.39, \"W\":-0.85, \"Y\":-0.52, \"V\":-0.03}\n",
    "}\n",
    "\n",
    "# Function info here ...\n",
    "def import_fa(file_name, return_labels=False):\n",
    "    print(\"Importing \"+file_name)\n",
    "    # List storage for file contents (sequences) and sequene labels\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    num_classes = 0\n",
    "    class_counts = [0]\n",
    "    # Try to open the file as read only\n",
    "    try:\n",
    "        file = open(file_name, \"r\")\n",
    "    # If the file would not open, print error message and exit\n",
    "    except:\n",
    "        print(\"\\nError: Could not open file\")\n",
    "        print(\"File name given: \"+file_name+\"\\n\")\n",
    "        raise SystemExit\n",
    "    # Iterate over all the lines in the file\n",
    "    for line in file.readlines():\n",
    "        # If this character is at the start of the line, it is a sequence label\n",
    "        if line[0] == \">\":\n",
    "            # If the argument 'return_labels' is True, append the label to a list\n",
    "            if return_labels:\n",
    "                labels.append(str(line)[1:-1])\n",
    "            else:\n",
    "                continue\n",
    "        elif \"class\" in line:\n",
    "            class_counts.append(0)\n",
    "            num_classes += 1\n",
    "        else:\n",
    "            class_counts[num_classes] += 1\n",
    "        # Append the sequence to the list of sequences\n",
    "        sequences.append(str(line)[:-1])\n",
    "    print(\"    \"+str(num_classes)+\" classes\")\n",
    "    print(\"    \"+str(len(sequences)-num_classes)+\" sequences\")\n",
    "    print(\"    \"+str(np.array(class_counts)[1:])+\" class counts\")\n",
    "    # If the argument 'return_labels' is True, return arrays of the sequences and labels\n",
    "    if return_labels:\n",
    "        return np.array(sequences), np.array(labels)\n",
    "    # If False, only return an array of the sequences\n",
    "    else:\n",
    "        return np.array(sequences)\n",
    "\n",
    "# Function info here ...\n",
    "def raw_to_features(data,resample=1.0,balance=False):\n",
    "    print(\"\\nConverting to features:\")\n",
    "    num_VHSE = len(VHSE_descriptors)\n",
    "    num_AA = len(amino_acids)\n",
    "    num_features = num_AA + num_VHSE\n",
    "    n = len(data)\n",
    "    # Find basic data stats for function use:\n",
    "    #   the max length sequence in the data\n",
    "    #   the number of classes\n",
    "    #   count of each class\n",
    "    max_seq_len = 0\n",
    "    class_counts = [0]\n",
    "    num_classes = -1\n",
    "    # Iterate over all sequences to count num classes, class frequencies, and the max sequence length\n",
    "    for line in data:\n",
    "        # Look out for a new class\n",
    "        if \"class\" in line:\n",
    "            class_counts.append(0)\n",
    "            num_classes += 1\n",
    "            continue\n",
    "        # Skip labels\n",
    "        elif line[0] == \">\":\n",
    "            continue\n",
    "        # Update max sequence length\n",
    "        if len(line) > max_seq_len:\n",
    "            max_seq_len = len(line)\n",
    "        # Update class counts\n",
    "        class_counts[num_classes+1] += 1\n",
    "    \n",
    "    # Since this was -1 based, increment to convert to 0 based count\n",
    "    num_classes += 1\n",
    "    n -= num_classes\n",
    "    \n",
    "    # Print stats found above\n",
    "    print(\"  Num Classes:\", num_classes)\n",
    "    print(\"  Class Counts:\")\n",
    "    frmt = \"{:>7}\"*num_classes\n",
    "    print(\" \"+frmt.format(*[i for i in range(num_classes)]))\n",
    "    print(\"   \",end=\"\")\n",
    "    frmt = \"{:>7}\"*num_classes\n",
    "    print(\" \"+frmt.format(*[class_counts[i] for i in range(1,num_classes+1)]))\n",
    "\n",
    "    # Split data by class for resampling\n",
    "    data_by_class = []\n",
    "    start_idx = 1\n",
    "    end_idx = start_idx + class_counts[1]\n",
    "    for i in range(num_classes):\n",
    "        new_class = data[start_idx+1:end_idx]\n",
    "        np.random.shuffle(new_class)\n",
    "        data_by_class.append( new_class )\n",
    "        if i < num_classes-1:\n",
    "          #print(start_idx, end_idx, class_counts[i+2], class_counts)\n",
    "          start_idx += end_idx\n",
    "          end_idx = start_idx + class_counts[i+2]\n",
    "\n",
    "    #print(\"data by class:\",data_by_class)\n",
    "\n",
    "    # Init variables for resampling\n",
    "    total_per_class = 0\n",
    "    num_samples = n\n",
    "    # If resampling:\n",
    "    if resample != 1.0:\n",
    "        # Calculate the size of the resampled dataset\n",
    "        num_samples = int(n*resample)\n",
    "        # If balanced classs coutns are required:\n",
    "        if balance:\n",
    "            # Calculate a balanced total number of instances per class\n",
    "            total_per_class = int(num_samples/num_classes)\n",
    "            if total_per_class > min(np.array(class_counts)[1:]):\n",
    "                total_per_class = min(np.array(class_counts)[1:])\n",
    "            #print(\"\\ntotal/class:\", total_per_class, \"\\n\")\n",
    "            for i in range(len(data_by_class)):\n",
    "                indexes = np.random.default_rng().choice(len(data_by_class[i]), size=total_per_class-1, replace=False)\n",
    "                #print(\"idxs:\",indexes)\n",
    "                data_by_class[i] = data_by_class[i][indexes]\n",
    "            \n",
    "        # If imbalanced class counts are acceptable\n",
    "        else:\n",
    "            # Calculate the total number of instances per class in the same ratio as class counts\n",
    "            total_per_class = [int(num_samples*class_counts[i+1]/n) for i in range(num_classes)]\n",
    "            #print(\"total/class:\",total_per_class)\n",
    "            for i in range(len(data_by_class)):\n",
    "                indexes = np.random.default_rng().choice(len(data_by_class[i]), size=total_per_class[i]-1, replace=False)\n",
    "                data_by_class[i] = data_by_class[i][indexes]\n",
    "            \n",
    "        print(\"  Resampling:\")\n",
    "        print(\"    Dataset size :\",n)\n",
    "        print(\"    Total/class  :\",total_per_class)\n",
    "        print(\"    Total samples:\",total_per_class*num_classes)\n",
    "        print()\n",
    "    # If not resampling\n",
    "    # TODO:  Complete - could the above be used instead of conditional?\n",
    "    else:\n",
    "        total_per_class = int(n/num_classes)\n",
    "    \n",
    "    #print(\"data by class:\",data_by_class)\n",
    "    \n",
    "    # Instantiate storage of features and labels\n",
    "    X = []\n",
    "    y = []\n",
    "      \n",
    "    # Convert from strings to arrays and pad the sequences with zeros to \n",
    "    # the length of the maximum length sequence; this is the number of features\n",
    "    index = 0\n",
    "    for i in range(len(data_by_class)):\n",
    "        for j in range(len(data_by_class[i])):\n",
    "            # Instantiate new array of zeros\n",
    "            new_instance = []\n",
    "            for k in range(num_VHSE):\n",
    "                new_instance.append([-999 for acid in range(max_seq_len)])\n",
    "            for k in range(num_AA):\n",
    "                new_instance.append([0 for acid in range(max_seq_len)])\n",
    "            # Fill in sequence\n",
    "            for k in range(len(data_by_class[i][j])):\n",
    "                acid_char = data_by_class[i][j][k]\n",
    "                if acid_char in amino_acids:\n",
    "                    for l in range(num_VHSE):\n",
    "                        new_instance[l][k] = VHSE_descriptors[l][acid_char]\n",
    "                    new_instance[amino_acids[acid_char]+num_VHSE][k] = 1\n",
    "            # Store new sequence in features store X\n",
    "            X.append(new_instance)\n",
    "            y.append(i)\n",
    "            index += 1\n",
    "\n",
    "    # Return features and labels\n",
    "    return np.array(X),np.array(y),max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d8b990a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 19:55:58.386265: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-14 19:55:58.386319: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data/pos_neg.fa\n",
      "    2 classes\n",
      "    56108 sequences\n",
      "    [ 3258 52850] class counts\n",
      "\n",
      "Converting to features:\n",
      "  Num Classes: 2\n",
      "  Class Counts:\n",
      "       0      1\n",
      "       3258  52850\n",
      "  Resampling:\n",
      "    Dataset size : 56108\n",
      "    Total/class  : 3258\n",
      "    Total samples: 6516\n",
      "\n",
      "Time taken: 214.769 sec\n",
      "shape of X: (6514, 28, 5537)\n",
      "shape of y: (6514,)\n"
     ]
    }
   ],
   "source": [
    "# For model loading\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# Import the data and extract features\n",
    "import time\n",
    "start = time.time()\n",
    "data = import_fa(\"data/pos_neg.fa\")\n",
    "X, y, seq_len = raw_to_features(data, resample=0.3, balance=True)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time taken:\", round(end-start,3),\"sec\")\n",
    "print(\"shape of X:\",np.shape(X))\n",
    "print(\"shape of y:\",np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3cab548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For one-hot encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert y to one-hot encoding for the CNN \n",
    "y_one_hot = to_categorical(y)\n",
    "\n",
    "# Split the data into train, test, and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, valid_X, y_one_hot, valid_y = train_test_split(X, y_one_hot, test_size=0.99, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84f94e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation samples: 6449\n",
      "(6449, 28, 5537)\n",
      "(6449, 2)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "No file or directory found at C:\\Users\\PrimeLabs\\Desktop\\ubl\\21.12.13_model_imbalanced",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12963/1251624046.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Imbalanced data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"C:\\Users\\PrimeLabs\\Desktop\\ubl\\21.12.13_model_imbalanced\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Evaluate the model with the final evaluation testing set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'No file or directory found at {filepath}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_hdf5_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             raise ImportError(\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at C:\\Users\\PrimeLabs\\Desktop\\ubl\\21.12.13_model_imbalanced"
     ]
    }
   ],
   "source": [
    "print(\"Number of validation samples:\",len(valid_X))\n",
    "print(np.shape(valid_X))\n",
    "print(np.shape(valid_y))\n",
    "\n",
    "# Imbalanced data\n",
    "model = keras.models.load_model(\"/home/chris/Desktop/ubl/21.12.13_model_imbalanced\")\n",
    "\n",
    "# Evaluate the model with the final evaluation testing set\n",
    "model.evaluate(valid_X, valid_y)\n",
    "# Get predictions and print confusion matrix\n",
    "results = model.predict(valid_X)\n",
    "# Store predictions for confusion matrix\n",
    "predictions = np.zeros(len(results))\n",
    "observed = np.zeros(len(valid_y))\n",
    "threshold = 0.5\n",
    "for i in range(len(results)):\n",
    "    if results[i][0] > threshold:\n",
    "        predictions[i] = 0\n",
    "    else:\n",
    "        predictions[i] = 1\n",
    "    if valid_y[i][1] == 1:\n",
    "        observed[i] = 1\n",
    "# print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print( confusion_matrix(observed, predictions) )\n",
    "\n",
    "# Balanced data\n",
    "model = keras.models.load_model(\"/home/chris/Desktop/ubl/21.12.13_model\")\n",
    "\n",
    "# Evaluate the model with the final evaluation testing set\n",
    "model.evaluate(valid_X, valid_y)\n",
    "# Get predictions and print confusion matrix\n",
    "results = model.predict(valid_X)\n",
    "# Store predictions for confusion matrix\n",
    "predictions = np.zeros(len(results))\n",
    "observed = np.zeros(len(valid_y))\n",
    "threshold = 0.5\n",
    "for i in range(len(results)):\n",
    "    if results[i][0] > threshold:\n",
    "        predictions[i] = 0\n",
    "    else:\n",
    "        predictions[i] = 1\n",
    "    if valid_y[i][1] == 1:\n",
    "        observed[i] = 1\n",
    "# print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print( confusion_matrix(observed, predictions) )\n",
    "\n",
    "# Zinc finger inclusive model\n",
    "model = keras.models.load_model(\"/home/chris/Desktop/ubl/21.12.13_model_zinc\")\n",
    "\n",
    "# Evaluate the model with the final evaluation testing set\n",
    "model.evaluate(valid_X, valid_y)\n",
    "# Get predictions and print confusion matrix\n",
    "results = model.predict(valid_X)\n",
    "# Store predictions for confusion matrix\n",
    "predictions = np.zeros(len(results))\n",
    "observed = np.zeros(len(valid_y))\n",
    "threshold = 0.5\n",
    "for i in range(len(results)):\n",
    "    if results[i][0] > threshold:\n",
    "        predictions[i] = 0\n",
    "    else:\n",
    "        predictions[i] = 1\n",
    "    if valid_y[i][1] == 1:\n",
    "        observed[i] = 1\n",
    "# print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print( confusion_matrix(observed, predictions) )\n",
    "\n",
    "# Zinc finger and UBL only model\n",
    "model = keras.models.load_model(\"/home/chris/Desktop/ubl/21.12.13_model_ubl-zinc\")\n",
    "\n",
    "# Evaluate the model with the final evaluation testing set\n",
    "model.evaluate(valid_X, valid_y)\n",
    "# Get predictions and print confusion matrix\n",
    "results = model.predict(valid_X)\n",
    "# Store predictions for confusion matrix\n",
    "predictions = np.zeros(len(results))\n",
    "observed = np.zeros(len(valid_y))\n",
    "threshold = 0.5\n",
    "for i in range(len(results)):\n",
    "    if results[i][0] > threshold:\n",
    "        predictions[i] = 0\n",
    "    else:\n",
    "        predictions[i] = 1\n",
    "    if valid_y[i][1] == 1:\n",
    "        observed[i] = 1\n",
    "# print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print( confusion_matrix(observed, predictions) )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
